{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FiQA Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we aim to analyze the sentiment of news headlines related to the financial field, utilizing cutting-edge NLP techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>22</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>36</th>\n",
       "      <th>38</th>\n",
       "      <th>40</th>\n",
       "      <th>...</th>\n",
       "      <th>1737</th>\n",
       "      <th>1741</th>\n",
       "      <th>1742</th>\n",
       "      <th>1743</th>\n",
       "      <th>1748</th>\n",
       "      <th>1750</th>\n",
       "      <th>1754</th>\n",
       "      <th>1755</th>\n",
       "      <th>1764</th>\n",
       "      <th>1779</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentence</th>\n",
       "      <td>Royal Mail chairman Donald Brydon set to step ...</td>\n",
       "      <td>Stakes High for AstraZeneca Heart Drug Facing ...</td>\n",
       "      <td>UPDATE 1-Dairy Crest loses a third of Morrison...</td>\n",
       "      <td>Insight hires Aviva's David Hillier for multi-...</td>\n",
       "      <td>Primark racks up a happy Christmas after stron...</td>\n",
       "      <td>UPDATE 1-Pearson expects to grow this year aft...</td>\n",
       "      <td>Tesco sells Blinkbox and broadband service to ...</td>\n",
       "      <td>Unilever profit rises despite sales slump in C...</td>\n",
       "      <td>Tesco leads leap in FTSE 100; Marks &amp; Spencer ...</td>\n",
       "      <td>Royal Dutch Shell profit rises; dividend up 4%</td>\n",
       "      <td>...</td>\n",
       "      <td>Berkshire seeks to boost its Wells Fargo stake...</td>\n",
       "      <td>Tesco share price tumbles after negative broke...</td>\n",
       "      <td>London Stock Exchange Shareholders Approve Mer...</td>\n",
       "      <td>UPDATE 1-Berkshire applies to boost Wells Farg...</td>\n",
       "      <td>Berkshire applies to boost Wells Fargo stake a...</td>\n",
       "      <td>Aviva, M&amp;G suspend property funds as investors...</td>\n",
       "      <td>UK housing market steadies after Brexit dip, P...</td>\n",
       "      <td>BRIEF-Aviva aims to increase dividend pay-out ...</td>\n",
       "      <td>Builder Persimmon hails 6% rise in house sales</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>info</th>\n",
       "      <td>[{'snippets': '['set to step down']', 'target'...</td>\n",
       "      <td>[{'snippets': '['Facing Tough Competition']', ...</td>\n",
       "      <td>[{'snippets': '['Crest loses a third of Morris...</td>\n",
       "      <td>[{'snippets': '['hires Aviva's David Hillier f...</td>\n",
       "      <td>[{'snippets': '['after strong sales']', 'targe...</td>\n",
       "      <td>[{'snippets': '['to grow this year after solid...</td>\n",
       "      <td>[{'snippets': '['sells Blinkbox and broadband ...</td>\n",
       "      <td>[{'snippets': '['despite sales slump']', 'targ...</td>\n",
       "      <td>[{'snippets': '['Tesco leads leap in FTSE 100;...</td>\n",
       "      <td>[{'snippets': '['dividend up 4%']', 'target': ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'snippets': '['seeks to boost its Wells Farg...</td>\n",
       "      <td>[{'snippets': '['share price tumbles a']', 'ta...</td>\n",
       "      <td>[{'snippets': '['Shareholders Approve Merger W...</td>\n",
       "      <td>[{'snippets': '['applies to boost Wells Fargo ...</td>\n",
       "      <td>[{'snippets': '['applies to boost Wells Fargo ...</td>\n",
       "      <td>[{'snippets': '['M&amp;G suspend property funds as...</td>\n",
       "      <td>[{'snippets': '['housing market']', 'target': ...</td>\n",
       "      <td>[{'snippets': '['increase dividend pay-out']',...</td>\n",
       "      <td>[{'snippets': '['6% rise in house sales']', 't...</td>\n",
       "      <td>[{'snippets': '['attracts more passengers']', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 436 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       1     \\\n",
       "sentence  Royal Mail chairman Donald Brydon set to step ...   \n",
       "info      [{'snippets': '['set to step down']', 'target'...   \n",
       "\n",
       "                                                       7     \\\n",
       "sentence  Stakes High for AstraZeneca Heart Drug Facing ...   \n",
       "info      [{'snippets': '['Facing Tough Competition']', ...   \n",
       "\n",
       "                                                       8     \\\n",
       "sentence  UPDATE 1-Dairy Crest loses a third of Morrison...   \n",
       "info      [{'snippets': '['Crest loses a third of Morris...   \n",
       "\n",
       "                                                       22    \\\n",
       "sentence  Insight hires Aviva's David Hillier for multi-...   \n",
       "info      [{'snippets': '['hires Aviva's David Hillier f...   \n",
       "\n",
       "                                                       30    \\\n",
       "sentence  Primark racks up a happy Christmas after stron...   \n",
       "info      [{'snippets': '['after strong sales']', 'targe...   \n",
       "\n",
       "                                                       31    \\\n",
       "sentence  UPDATE 1-Pearson expects to grow this year aft...   \n",
       "info      [{'snippets': '['to grow this year after solid...   \n",
       "\n",
       "                                                       32    \\\n",
       "sentence  Tesco sells Blinkbox and broadband service to ...   \n",
       "info      [{'snippets': '['sells Blinkbox and broadband ...   \n",
       "\n",
       "                                                       36    \\\n",
       "sentence  Unilever profit rises despite sales slump in C...   \n",
       "info      [{'snippets': '['despite sales slump']', 'targ...   \n",
       "\n",
       "                                                       38    \\\n",
       "sentence  Tesco leads leap in FTSE 100; Marks & Spencer ...   \n",
       "info      [{'snippets': '['Tesco leads leap in FTSE 100;...   \n",
       "\n",
       "                                                       40    ...  \\\n",
       "sentence     Royal Dutch Shell profit rises; dividend up 4%  ...   \n",
       "info      [{'snippets': '['dividend up 4%']', 'target': ...  ...   \n",
       "\n",
       "                                                       1737  \\\n",
       "sentence  Berkshire seeks to boost its Wells Fargo stake...   \n",
       "info      [{'snippets': '['seeks to boost its Wells Farg...   \n",
       "\n",
       "                                                       1741  \\\n",
       "sentence  Tesco share price tumbles after negative broke...   \n",
       "info      [{'snippets': '['share price tumbles a']', 'ta...   \n",
       "\n",
       "                                                       1742  \\\n",
       "sentence  London Stock Exchange Shareholders Approve Mer...   \n",
       "info      [{'snippets': '['Shareholders Approve Merger W...   \n",
       "\n",
       "                                                       1743  \\\n",
       "sentence  UPDATE 1-Berkshire applies to boost Wells Farg...   \n",
       "info      [{'snippets': '['applies to boost Wells Fargo ...   \n",
       "\n",
       "                                                       1748  \\\n",
       "sentence  Berkshire applies to boost Wells Fargo stake a...   \n",
       "info      [{'snippets': '['applies to boost Wells Fargo ...   \n",
       "\n",
       "                                                       1750  \\\n",
       "sentence  Aviva, M&G suspend property funds as investors...   \n",
       "info      [{'snippets': '['M&G suspend property funds as...   \n",
       "\n",
       "                                                       1754  \\\n",
       "sentence  UK housing market steadies after Brexit dip, P...   \n",
       "info      [{'snippets': '['housing market']', 'target': ...   \n",
       "\n",
       "                                                       1755  \\\n",
       "sentence  BRIEF-Aviva aims to increase dividend pay-out ...   \n",
       "info      [{'snippets': '['increase dividend pay-out']',...   \n",
       "\n",
       "                                                       1764  \\\n",
       "sentence     Builder Persimmon hails 6% rise in house sales   \n",
       "info      [{'snippets': '['6% rise in house sales']', 't...   \n",
       "\n",
       "                                                       1779  \n",
       "sentence  EasyJet attracts more passengers in June but s...  \n",
       "info      [{'snippets': '['attracts more passengers']', ...  \n",
       "\n",
       "[2 rows x 436 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_df = pd.read_json(\"data/FiQA_ABSA_task1/task1_headline_ABSA_train.json\")\n",
    "headline_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>14860</th>\n",
       "      <th>14864</th>\n",
       "      <th>14867</th>\n",
       "      <th>14875</th>\n",
       "      <th>14876</th>\n",
       "      <th>14877</th>\n",
       "      <th>14880</th>\n",
       "      <th>14882</th>\n",
       "      <th>14886</th>\n",
       "      <th>14891</th>\n",
       "      <th>...</th>\n",
       "      <th>19103</th>\n",
       "      <th>19105</th>\n",
       "      <th>19107</th>\n",
       "      <th>19117</th>\n",
       "      <th>19119</th>\n",
       "      <th>19130</th>\n",
       "      <th>19149</th>\n",
       "      <th>19161</th>\n",
       "      <th>19163</th>\n",
       "      <th>19167</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentence</th>\n",
       "      <td>Slowly adding some $FIO here but gotta be care...</td>\n",
       "      <td>$TRX http://stks.co/1KkK Long setup. MACD cross.</td>\n",
       "      <td>I am not optimistic about $amzn both fundement...</td>\n",
       "      <td>$GRPN might be selling off ahead of $P earning...</td>\n",
       "      <td>$IACI http://stks.co/tJU Looks good on the wee...</td>\n",
       "      <td>$pcln back over \"up\" trendline from 10/4</td>\n",
       "      <td>RT @robbieLOLZ $NFLX A close above here is loo...</td>\n",
       "      <td>Profit taking on $AAPL this morning?  That has...</td>\n",
       "      <td>$SKX turning. Coming from far could go far. St...</td>\n",
       "      <td>$MOS looking good here at $58.65. Calls are ac...</td>\n",
       "      <td>...</td>\n",
       "      <td>Breaking 52 week highs timing looks great now ...</td>\n",
       "      <td>$TSLA recalling pretty much every single model...</td>\n",
       "      <td>$aapl high of day just hit. Back at it tomorrow.</td>\n",
       "      <td>ouch looks like $tsla shorts getting skinned a...</td>\n",
       "      <td>Qualcomm: 10% Dividend Increase Rewards Patien...</td>\n",
       "      <td>Facebook $FB received a Buy rating from Wells ...</td>\n",
       "      <td>$TSLA Wish had my puts back but see if we can ...</td>\n",
       "      <td>Citrix Systems Inc $CTXS Position Increased by...</td>\n",
       "      <td>Notable gainers among liquid option names this...</td>\n",
       "      <td>Is #Facebook's user engagement falling? https:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>info</th>\n",
       "      <td>[{'snippets': '['Slowly adding some $FIO here ...</td>\n",
       "      <td>[{'snippets': '['Long setup. MACD cross.']', '...</td>\n",
       "      <td>[{'snippets': '['both fundementals and charts ...</td>\n",
       "      <td>[{'snippets': '['might be selling off ahead']'...</td>\n",
       "      <td>[{'snippets': '['Looks good on the weekly char...</td>\n",
       "      <td>[{'snippets': '['back over \"up\" trendline']', ...</td>\n",
       "      <td>[{'snippets': '['A close above here is looking...</td>\n",
       "      <td>[{'snippets': '['That has to be the pressure o...</td>\n",
       "      <td>[{'snippets': '['Stock price implies you pay n...</td>\n",
       "      <td>[{'snippets': '['Calls are active in this mont...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'snippets': '['Breaking 52 week highs timing...</td>\n",
       "      <td>[{'snippets': '['ecalling pretty much every si...</td>\n",
       "      <td>[{'snippets': '['high of day just hit.']', 'se...</td>\n",
       "      <td>[{'snippets': '['shorts getting skinned again'...</td>\n",
       "      <td>[{'snippets': '['Dividend Increase Rewards Pat...</td>\n",
       "      <td>[{'snippets': '['received a Buy rating']', 'se...</td>\n",
       "      <td>[{'snippets': '['if we can find support around...</td>\n",
       "      <td>[{'snippets': '['Position Increased by Mizuho'...</td>\n",
       "      <td>[{'snippets': '['Notable gainers among liquid ...</td>\n",
       "      <td>[{'snippets': '[\"Is #Facebook's user engagemen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 675 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      14860  \\\n",
       "sentence  Slowly adding some $FIO here but gotta be care...   \n",
       "info      [{'snippets': '['Slowly adding some $FIO here ...   \n",
       "\n",
       "                                                      14864  \\\n",
       "sentence   $TRX http://stks.co/1KkK Long setup. MACD cross.   \n",
       "info      [{'snippets': '['Long setup. MACD cross.']', '...   \n",
       "\n",
       "                                                      14867  \\\n",
       "sentence  I am not optimistic about $amzn both fundement...   \n",
       "info      [{'snippets': '['both fundementals and charts ...   \n",
       "\n",
       "                                                      14875  \\\n",
       "sentence  $GRPN might be selling off ahead of $P earning...   \n",
       "info      [{'snippets': '['might be selling off ahead']'...   \n",
       "\n",
       "                                                      14876  \\\n",
       "sentence  $IACI http://stks.co/tJU Looks good on the wee...   \n",
       "info      [{'snippets': '['Looks good on the weekly char...   \n",
       "\n",
       "                                                      14877  \\\n",
       "sentence           $pcln back over \"up\" trendline from 10/4   \n",
       "info      [{'snippets': '['back over \"up\" trendline']', ...   \n",
       "\n",
       "                                                      14880  \\\n",
       "sentence  RT @robbieLOLZ $NFLX A close above here is loo...   \n",
       "info      [{'snippets': '['A close above here is looking...   \n",
       "\n",
       "                                                      14882  \\\n",
       "sentence  Profit taking on $AAPL this morning?  That has...   \n",
       "info      [{'snippets': '['That has to be the pressure o...   \n",
       "\n",
       "                                                      14886  \\\n",
       "sentence  $SKX turning. Coming from far could go far. St...   \n",
       "info      [{'snippets': '['Stock price implies you pay n...   \n",
       "\n",
       "                                                      14891  ...  \\\n",
       "sentence  $MOS looking good here at $58.65. Calls are ac...  ...   \n",
       "info      [{'snippets': '['Calls are active in this mont...  ...   \n",
       "\n",
       "                                                      19103  \\\n",
       "sentence  Breaking 52 week highs timing looks great now ...   \n",
       "info      [{'snippets': '['Breaking 52 week highs timing...   \n",
       "\n",
       "                                                      19105  \\\n",
       "sentence  $TSLA recalling pretty much every single model...   \n",
       "info      [{'snippets': '['ecalling pretty much every si...   \n",
       "\n",
       "                                                      19107  \\\n",
       "sentence   $aapl high of day just hit. Back at it tomorrow.   \n",
       "info      [{'snippets': '['high of day just hit.']', 'se...   \n",
       "\n",
       "                                                      19117  \\\n",
       "sentence  ouch looks like $tsla shorts getting skinned a...   \n",
       "info      [{'snippets': '['shorts getting skinned again'...   \n",
       "\n",
       "                                                      19119  \\\n",
       "sentence  Qualcomm: 10% Dividend Increase Rewards Patien...   \n",
       "info      [{'snippets': '['Dividend Increase Rewards Pat...   \n",
       "\n",
       "                                                      19130  \\\n",
       "sentence  Facebook $FB received a Buy rating from Wells ...   \n",
       "info      [{'snippets': '['received a Buy rating']', 'se...   \n",
       "\n",
       "                                                      19149  \\\n",
       "sentence  $TSLA Wish had my puts back but see if we can ...   \n",
       "info      [{'snippets': '['if we can find support around...   \n",
       "\n",
       "                                                      19161  \\\n",
       "sentence  Citrix Systems Inc $CTXS Position Increased by...   \n",
       "info      [{'snippets': '['Position Increased by Mizuho'...   \n",
       "\n",
       "                                                      19163  \\\n",
       "sentence  Notable gainers among liquid option names this...   \n",
       "info      [{'snippets': '['Notable gainers among liquid ...   \n",
       "\n",
       "                                                      19167  \n",
       "sentence  Is #Facebook's user engagement falling? https:...  \n",
       "info      [{'snippets': '[\"Is #Facebook's user engagemen...  \n",
       "\n",
       "[2 rows x 675 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df = pd.read_json(\"data/FiQA_ABSA_task1/task1_post_ABSA_train.json\")\n",
    "post_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import rcParams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "# plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FiqaEDA:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.df = None\n",
    "        self.aspect_hierarchy = []\n",
    "        \n",
    "    def _load_and_preprocess(self):\n",
    "        \"\"\"Load JSON data and convert to structured DataFrame\"\"\"\n",
    "        with open(self.filepath) as f:\n",
    "            raw_data = json.load(f)\n",
    "        \n",
    "        records = []\n",
    "        for entry_id, content in raw_data.items():\n",
    "            base_entry = {\n",
    "                'id': entry_id,\n",
    "                'sentence': content['sentence']\n",
    "            }\n",
    "            for info in content['info']:\n",
    "                record = base_entry.copy()\n",
    "                record.update({\n",
    "                    'snippets': ast.literal_eval(info['snippets']),\n",
    "                    'target': info['target'],\n",
    "                    'sentiment_score': float(info['sentiment_score']),\n",
    "                    'aspects': ast.literal_eval(info['aspects'])\n",
    "                })\n",
    "                records.append(record)\n",
    "                \n",
    "        self.df = pd.DataFrame(records)\n",
    "        self._enhance_data()\n",
    "\n",
    "    def _enhance_data(self):\n",
    "        \"\"\"Create additional features and clean data\"\"\"\n",
    "        # Sentiment classification\n",
    "        bins = [-1, -0.33, 0.33, 1]\n",
    "        labels = ['negative', 'neutral', 'positive']\n",
    "        self.df['sentiment_class'] = pd.cut(self.df['sentiment_score'], \n",
    "                                          bins=bins, labels=labels)\n",
    "        \n",
    "        # Aspect hierarchy processing\n",
    "        self.df['primary_aspect'] = self.df['aspects'].apply(\n",
    "            lambda x: x[0].split('/')[0] if len(x) > 0 else 'unknown'\n",
    "        )\n",
    "        self.df['secondary_aspect'] = self.df['aspects'].apply(\n",
    "            lambda x: x[0].split('/')[1] if len(x[0].split('/')) > 1 else 'none'\n",
    "        )\n",
    "        \n",
    "        # Text processing\n",
    "        self.df['snippet_text'] = self.df['snippets'].str.join(' ')\n",
    "\n",
    "    def _validate_data(self):\n",
    "        \"\"\"Data quality checks\"\"\"\n",
    "        print(\"=== Data Validation Report ===\")\n",
    "        print(f\"Total entries: {len(self.df)}\")\n",
    "        print(\"\\nMissing values:\")\n",
    "        print(self.df.isnull().sum())\n",
    "        \n",
    "        # Check for invalid sentiment scores\n",
    "        invalid_scores = self.df[~self.df['sentiment_score'].between(-1, 1)]\n",
    "        print(f\"\\nInvalid sentiment scores: {len(invalid_scores)}\")\n",
    "\n",
    "    def analyze_sentiment_distribution(self):\n",
    "        \"\"\"Generate sentiment visualizations\"\"\"\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(self.df['sentiment_score'], bins=20, kde=True)\n",
    "        plt.title('Sentiment Score Distribution')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        self.df['sentiment_class'].value_counts().plot(kind='bar')\n",
    "        plt.title('Sentiment Class Distribution')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def analyze_aspects(self):\n",
    "        \"\"\"Aspect category analysis\"\"\"\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        # Primary aspects\n",
    "        primary_counts = self.df['primary_aspect'].value_counts()\n",
    "        sns.barplot(y=primary_counts.index, x=primary_counts.values, ax=ax[0])\n",
    "        ax[0].set_title('Primary Aspect Distribution')\n",
    "        \n",
    "        # Secondary aspects (top 15)\n",
    "        secondary_counts = self.df['secondary_aspect'].value_counts().head(15)\n",
    "        sns.barplot(y=secondary_counts.index, x=secondary_counts.values, ax=ax[1])\n",
    "        ax[1].set_title('Top 15 Secondary Aspects')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def generate_word_clouds(self):\n",
    "        \"\"\"Generate sentiment-specific word clouds\"\"\"\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        for i, sentiment in enumerate(['positive', 'neutral', 'negative']):\n",
    "            text = ' '.join(self.df[self.df['sentiment_class'] == sentiment]['snippet_text'])\n",
    "            wc = WordCloud(\n",
    "                width=400, \n",
    "                height=400, \n",
    "                background_color='white',\n",
    "                colormap='viridis' if sentiment == 'neutral' else \n",
    "                        'Greens' if sentiment == 'positive' else 'Reds'\n",
    "            ).generate(text)\n",
    "            \n",
    "            ax[i].imshow(wc)\n",
    "            ax[i].set_title(f'{sentiment.capitalize()} Sentiment Terms')\n",
    "            ax[i].axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    def analyze_targets(self):\n",
    "        \"\"\"Company/organization analysis\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        target_counts = self.df['target'].value_counts().head(10)\n",
    "        sns.barplot(y=target_counts.index, x=target_counts.values)\n",
    "        plt.title('Top 10 Frequently Mentioned Targets')\n",
    "        plt.show()\n",
    "\n",
    "    def run_full_analysis(self):\n",
    "        \"\"\"Execute complete EDA pipeline\"\"\"\n",
    "        self._load_and_preprocess()\n",
    "        self._validate_data()\n",
    "        \n",
    "        print(\"\\n=== Basic Statistics ===\")\n",
    "        print(self.df.describe(include='all'))\n",
    "        \n",
    "        self.analyze_sentiment_distribution()\n",
    "        self.analyze_aspects()\n",
    "        self.generate_word_clouds()\n",
    "        self.analyze_targets()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
